{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnkA6fazG2Eh"
      },
      "source": [
        "# PyTorch: Variable, Gradientes e Grafo Computacional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdiT8nGeG2Ek"
      },
      "source": [
        "## Objetivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDEX9Mk8G2Em"
      },
      "source": [
        "Este notebook introduz\n",
        "- o conceito de `Variables` do PyTorch,\n",
        "- uma interpretação numérica intuitiva do gradiente, e o\n",
        "- grafo computacional, utilizado para o cálculo automático do gradiente de uma função."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lPCM5vmG2Eo"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de\n",
        "calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada\n",
        "pelo tipo Variable do PyTorch, que adiciona ao tensor a facilidade de cálculo automático do gradiente pela construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLATrVDrG2Eq"
      },
      "source": [
        "## Grafo computacional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbH9rnZmG2Er"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tPYkCldG2Es"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/vcasadei/images/master/GrafoComputacional.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcNk_YSuhTfn"
      },
      "outputs": [],
      "source": [
        "X = [0 1 2 3]\n",
        "W = 1\n",
        "Y_pred = X*W = [0 1 2 3]\n",
        "Y = [0 2 4 6]\n",
        "e = Y_pred - Y = [0 1 2 3] - [0 2 4 6] = [0 -1 -2 -3]\n",
        "e^2 = [0 -1 -2 -3]^2 = [0 1 4 9]\n",
        "J = sum(e^2) = sum([0 1 4 9]) = 14 = J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnTsPEf6G2Eu"
      },
      "source": [
        "Variable possui 3 campos: o dado em si (data), o gradiente (grad) e um apontador (creator) para construir o grafo da backpropagation. Uma expressão utilizada para o cálculo do gradiente exige que todas suas expressões sejam calculadas com Variables, caso contrário não é possível construir o grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wI-LZc6G2Ev"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/vcasadei/images/master/variables.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.148492",
          "start_time": "2017-11-24T14:09:18.096752"
        },
        "id": "OJt_zc0CG2Ex"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JONBAEwzG2E4"
      },
      "source": [
        "## Variable é criada a partir de um tensor e possui as mesmas funcionalidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.305082",
          "start_time": "2017-11-24T14:09:19.150032"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT8CBLTaG2E6",
        "outputId": "dcb61ada-3cd9-4d29-88df-ba53259b509f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_t = 2 * torch.arange(0.,4.)\n",
        "y = Variable(y_t); y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.311537",
          "start_time": "2017-11-24T14:09:19.306712"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiSNffiPG2FD",
        "outputId": "84375c6c-1475-4eb9-8f57-2e21591a3619"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = Variable(torch.arange(0.,4.)); x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.318102",
          "start_time": "2017-11-24T14:09:19.313131"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW0pCsgaG2FK",
        "outputId": "dc626474-26b0-483c-9a10-3804987ff7b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = Variable(torch.ones(1),requires_grad=True); w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRXfFM2TG2FR"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFuPZhFGG2FU"
      },
      "source": [
        "Seja a expressão: $$ J = ((x  w) - y)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqNof23cG2FW"
      },
      "source": [
        "### Montagem do grafo computacional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.344631",
          "start_time": "2017-11-24T14:09:19.319779"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71lXNZ9mG2FX",
        "outputId": "dccbe159-39a9-478e-c1b0-162b306a4e45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14., grad_fn=<SumBackward0>)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y\n",
        "e2 = e.pow(2)\n",
        "J = e2.sum()\n",
        "J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elNRuA34G2Fe"
      },
      "source": [
        "## Auto grad - processa o grafo computacional backwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-04T15:55:45.308858",
          "start_time": "2017-10-04T15:55:45.304654"
        },
        "id": "y9mN5TqhG2Fm"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada e calcula o gradiente para todas as `Variables` que possuem o atributo `requires_grad` como verdadeiro.\n",
        "O `backward()` destroi o grafo após sua execução. Isso é intrínsico ao PyTorch pelo fato dele ser uma rede dinâmica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.355085",
          "start_time": "2017-11-24T14:09:19.346403"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrEXyjIDG2Fn",
        "outputId": "eb7399f2-5175-446f-8649-864c38101db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ],
      "source": [
        "J.backward()\n",
        "print(w.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.363848",
          "start_time": "2017-11-24T14:09:19.356800"
        },
        "id": "MwkCb8LYG2Fu"
      },
      "outputs": [],
      "source": [
        "w.grad.data.zero_();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9biEyEt1G2Fz"
      },
      "source": [
        "## Interpretação do Gradiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVaH2WFyG2F0"
      },
      "source": [
        "O gradiente de uma variável final (J) com respeito à outra variável de entrada (w) pode ser interpretado como o quanto a variável final J vai aumentar se houver um pequeno aumento na variável de entrada (w).\n",
        "Por exemplo suponha que o gradiente seja 28. Isto significa se aumentarmos a variável w de 0.001, então J vai aumentar de 0.028."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.372040",
          "start_time": "2017-11-24T14:09:19.365927"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnO_ImuHG2F2",
        "outputId": "004c0554-ba4d-4416-e536-258a80500d64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(13.9720, grad_fn=<SumBackward0>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eps = 0.001\n",
        "y_pred = x * (w+eps)\n",
        "J_new = (y_pred - y).pow(2).sum()\n",
        "J_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.403233",
          "start_time": "2017-11-24T14:09:19.373831"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ObOY_GnG2F8",
        "outputId": "52e7c3ac-8e97-4a4e-dd27-f8e2ef9ceacd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.027988434\n"
          ]
        }
      ],
      "source": [
        "print((J_new - J).data.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v625mnGlG2GC"
      },
      "source": [
        "## Back propagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryb4BtcGG2GF"
      },
      "source": [
        "Uma forma equivalente explícita de calcular o gradiente é fazendo o processamento do backpropagation no grafo computacional, de forma explícita.\n",
        "Apenas como ilustração.\n",
        "\n",
        "Função de perda:\n",
        "$$ J(\\hat{y_i},y_i) = \\frac{1}{M} \\sum_{i=0}^{M-1} (\\hat{y_i} - y_i)^2 $$\n",
        "\n",
        "Gradiente:\n",
        "$$  \\mathbf{\\nabla{J_w}} = \\frac{2}{M}\\mathbf{x^T}(\\mathbf{x w^T} - \\mathbf{y}) $$\n",
        "\n",
        "Atualização dos parâmetros pelo gradiente descendente:\n",
        "$$ \\mathbf{w} = \\mathbf{w} − \\eta (\\mathbf{\\nabla J_w})^T $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LetkxS-8jxO4"
      },
      "outputs": [],
      "source": [
        "J = 14\n",
        "dj = 2*[0 1 2 3]([0 1 2 3][1] - [0 2 4 6])\n",
        "dj = [0 2 4 6]([0 1 2 3] - [0 2 4 6])\n",
        "dj = [0 2 4 6]([0 -1 -2 -3])\n",
        "dj = [0 -2 -8 -18] = -28\n",
        "\n",
        "w_new = w - lr*dj\n",
        "w_new = [1] - 0.1*(-28) = 1 - (-2.8) = 1 + 2.8 = 3.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.413681",
          "start_time": "2017-11-24T14:09:19.405014"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXrz6a0EG2GH",
        "outputId": "651ef88a-8946-451f-b798-bc8bd088bcaa",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "[1. 1. 1. 1.]\n",
            "[ 0. -2. -4. -6.]\n",
            "-28.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "dJ = 1.\n",
        "de2 = dJ * np.ones((4,))\n",
        "de = de2 * 2 * e.data.numpy()\n",
        "dy_pred = de\n",
        "dw = (dy_pred * x.data.numpy()).sum()\n",
        "print(dJ)\n",
        "print(de2)\n",
        "print(de)\n",
        "print(dw)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pvsJc0tG2GR"
      },
      "source": [
        "## Visualizando o grafo computacional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jg-tSOvCMs1",
        "outputId": "83a04417-0398-4994-dbeb-e311ae7b14d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Collecting git+https://github.com/szagoruyko/pytorchviz\n",
            "  Cloning https://github.com/szagoruyko/pytorchviz to /tmp/pip-req-build-dqk8j3qf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/szagoruyko/pytorchviz /tmp/pip-req-build-dqk8j3qf\n",
            "  Resolved https://github.com/szagoruyko/pytorchviz to commit 0adcd83af8aa7ab36d6afd139cabbd9df598edb7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz==0.0.2) (2.3.0+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz==0.0.2) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torchviz==0.0.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz==0.0.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz==0.0.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz==0.0.2) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4972 sha256=0d0f217d8c0ce6ea36b86b66967289552e9725f68514e6f55543dbb208506b69\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qrrzb5un/wheels/44/5a/39/48c1209682afcfc7ad8ae7b3cf7aa0ff08a72e3ac4e5931f1d\n",
            "Successfully built torchviz\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torchviz-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install graphviz\n",
        "!pip install git+https://github.com/szagoruyko/pytorchviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "VRZi7-urCZZS",
        "outputId": "f2de635c-2450-4be4-efca-1d0c7336b9cf"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<!-- Generated by graphviz version 2.43.0 (0)\n",
              " -->\n",
              "<!-- Title: %3 Pages: 1 -->\n",
              "<svg width=\"109pt\" height=\"380pt\"\n",
              " viewBox=\"0.00 0.00 109.00 380.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 376)\">\n",
              "<title>%3</title>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-376 105,-376 105,4 -4,4\"/>\n",
              "<!-- 138719530755280 -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>138719530755280</title>\n",
              "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n",
              "<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
              "</g>\n",
              "<!-- 138716451831664 -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>138716451831664</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n",
              "<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
              "</g>\n",
              "<!-- 138716451831664&#45;&gt;138719530755280 -->\n",
              "<g id=\"edge6\" class=\"edge\">\n",
              "<title>138716451831664&#45;&gt;138719530755280</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n",
              "</g>\n",
              "<!-- 138716451831280 -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>138716451831280</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n",
              "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
              "</g>\n",
              "<!-- 138716451831280&#45;&gt;138716451831664 -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>138716451831280&#45;&gt;138716451831664</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n",
              "</g>\n",
              "<!-- 138716451831424 -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>138716451831424</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-196 6,-196 6,-177 95,-177 95,-196\"/>\n",
              "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
              "</g>\n",
              "<!-- 138716451831424&#45;&gt;138716451831280 -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>138716451831424&#45;&gt;138716451831280</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n",
              "</g>\n",
              "<!-- 138716451831520 -->\n",
              "<g id=\"node5\" class=\"node\">\n",
              "<title>138716451831520</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-251 6,-251 6,-232 95,-232 95,-251\"/>\n",
              "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
              "</g>\n",
              "<!-- 138716451831520&#45;&gt;138716451831424 -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>138716451831520&#45;&gt;138716451831424</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.75C50.5,-224.8 50.5,-214.85 50.5,-206.13\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.09 50.5,-196.09 47,-206.09 54,-206.09\"/>\n",
              "</g>\n",
              "<!-- 138716451831136 -->\n",
              "<g id=\"node6\" class=\"node\">\n",
              "<title>138716451831136</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-306 0,-306 0,-287 101,-287 101,-306\"/>\n",
              "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
              "</g>\n",
              "<!-- 138716451831136&#45;&gt;138716451831520 -->\n",
              "<g id=\"edge4\" class=\"edge\">\n",
              "<title>138716451831136&#45;&gt;138716451831520</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.75C50.5,-279.8 50.5,-269.85 50.5,-261.13\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.09 50.5,-251.09 47,-261.09 54,-261.09\"/>\n",
              "</g>\n",
              "<!-- 138716622582736 -->\n",
              "<g id=\"node7\" class=\"node\">\n",
              "<title>138716622582736</title>\n",
              "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-372 23.5,-372 23.5,-342 77.5,-342 77.5,-372\"/>\n",
              "<text text-anchor=\"middle\" x=\"50.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\">w</text>\n",
              "<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
              "</g>\n",
              "<!-- 138716622582736&#45;&gt;138716451831136 -->\n",
              "<g id=\"edge5\" class=\"edge\">\n",
              "<title>138716622582736&#45;&gt;138716451831136</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-341.84C50.5,-334.21 50.5,-324.7 50.5,-316.45\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"54,-316.27 50.5,-306.27 47,-316.27 54,-316.27\"/>\n",
              "</g>\n",
              "</g>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7e2970d5ffa0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchviz import make_dot, make_dot_from_trace\n",
        "J = ((w * x) - y).pow(2).sum()\n",
        "p = {'w':w} # dicionário de parâmetros\n",
        "out = make_dot(J,params=p)\n",
        "out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bIqUBct4G2Gg"
      },
      "source": [
        "# Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEfWG-e5G2Gh"
      },
      "source": [
        "## Questões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXLoZzF6G2Gj"
      },
      "source": [
        "1. Por que numa expressão computacional não é possível misturar `Variable` com tensores?\n",
        "2. O que acontece com o grafo computacional após execução do `backward()`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayWukpAIG2Gk"
      },
      "source": [
        "## Atividades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-06T22:02:17.474843Z",
          "start_time": "2017-10-06T22:02:17.468865Z"
        },
        "id": "k5Ayt5dAG2Gl"
      },
      "source": [
        "1. Execute um passo de atualização do valor de w, pelo\n",
        "gradiente descendente. Utilize um fator de aprendizado (*learning rate*) de 0.01\n",
        "para atualizar o `w`. Após, recalcule a função de perda:\n",
        "\n",
        "    - w = w - lr * w.grad.data\n",
        "    - execute a célula 1.3.1 e verifique o quanto que a perda J diminuiu\n",
        "    \n",
        "2. No trecho abaixo, uma rede bastante conhecida, `resnet18` contendo 18 camadas\n",
        "   é criada, tendo\n",
        "   como entrada `xin` que é convertida para `Variable`, resultando na saída `y`.\n",
        "   \n",
        "   Descomente a linha que cria a vizualização do grafo computacional e execute a\n",
        "   célula para visualizar o grafo computacional da rede `resnet18`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dados iniciais\n",
        "y_t = 2 * torch.arange(0., 4.)\n",
        "y = Variable(y_t)\n",
        "x = Variable(torch.arange(0., 4.))\n",
        "w = Variable(torch.ones(1), requires_grad=True)\n",
        "\n",
        "# Previsão inicial\n",
        "y_pred = x * w\n",
        "\n",
        "# Cálculo da perda inicial J\n",
        "e = y_pred - y\n",
        "e2 = e.pow(2)\n",
        "J = e2.sum()\n",
        "\n",
        "# Backward para calcular gradientes\n",
        "J.backward()\n",
        "\n",
        "# Passo de atualização para w pelo gradiente descendente\n",
        "lr = 0.1\n",
        "w.data = w.data - lr * w.grad.data #isso que tu precisa\n",
        "\n",
        "# Zerando o gradiente acumulado\n",
        "w.grad.data.zero_()\n",
        "\n",
        "# Recalculando a previsão e a perda após a atualização\n",
        "y_pred_new = x * w\n",
        "J_new = (y_pred_new - y).pow(2).sum()\n",
        "\n",
        "# Calculando a mudança na perda\n",
        "print(\"Mudança na perda J:\", (J_new - J).data.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-24T14:09:19.519949",
          "start_time": "2017-11-24T16:09:18.148Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKwW1oQ8G2Go",
        "outputId": "4a442e65-d051-4307-b66c-8d5a6ab05425",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision\n",
        "from torchvision import models\n",
        "xin = torch.randn(1,3,224,224)\n",
        "resnet18 = models.resnet18()\n",
        "y = resnet18(Variable(xin))\n",
        "# g = make_dot(y, dict(resnet18.named_parameters()))\n",
        "# g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S6srVMzG2G1"
      },
      "source": [
        "# Aprendizados com este notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "VyUo4FaAG2G2"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com tensores que têm requires_grad=True, o PyTorch consegue identificar as operações feitas nesses tensores e com isso calcular automaticamente os gradientes usando a diferenciação automática(autograd). Isso exclui a necessidade de calcular de forma manuaul os gradientes, simplificando o treinamento de modelos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "5fe3e6f0cdaab8afdc61c52912fda83f7c0a71baaea1897dd7498e2df01e69ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
